<img src="https://cdn.prod.website-files.com/677c400686e724409a5a7409/6790ad949cf622dc8dcd9fe4_nextwork-logo-leather.svg" alt="NextWork" width="300" />

# Build a RAG API with FastAPI

**Project Link:** [View Project](http://learn.nextwork.org/projects/ai-devops-api)

**Author:** Zay Yar Min Thu  
**Email:** zayyarminthu4@gmail.com

---

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_g3h4i5j6)

---

## Introducing Today's Project!

In this project, I will demonstrate how to build a Retrieval-Augmented Generation (RAG) API using FastAPI. I am doing this project to learn how to design, implement, and deploy AI-powered APIs that combine information retrieval with large language models.

### Key services and concepts

Services I used were FastAPI, Chroma, Ollama, and Uvicorn.
Key concepts I learned include retrieval-augmented generation (RAG), embeddings and vector search, API design, and integrating large language models into backend services.

### Challenges and wins

This project took me approximately. 20 minute The most challenging part was setting up knowledge base for the RAG system.

### Why I did this project

I did this project to demonstrate my ability to design and implement a RAG-based API using modern backend and AI tools.

---

## Setting Up Python and Ollama

In this step, I’m setting up Python and Ollama. Python is the language used to create the API, and Ollama allows me to run AI models locally. I need both to build and test the RAG system.

### Python and Ollama setup

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_i9j0k1l2)

### Verifying Python is working

### Ollama and tinyllama ready

Ollama is a local LLM runtime for running models on your machine. I chose the TinyLlama model because it is lightweight and efficient for development. The model supports my RAG API by generating responses grounded in retrieved context.

---

## Setting Up a Python Workspace

In this step, I’m setting up the project folder and creating a virtual environment. I need it because Python projects require isolated environments to keep dependencies separated and avoid package conflicts.

### Python workspace setup

### Virtual environment

A virtual environment is an isolated Python workspace for managing project dependencies. I created one to keep this project’s packages separate from the global environment. Once activated, all installs and executions occur inside it. I created the virtual environment using Python’s venv.

### Dependencies

The installed packages include FastAPI for API development, Chroma for vector storage and retrieval, Uvicorn for serving the application, and Ollama for local LLM inference.

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_u1v2w3x4)

---

## Setting Up a Knowledge Base

In this step, I’m creating a knowledge base. A knowledge base is a collection of documents used for retrieval. It is required so the RAG system can fetch relevant context before generating responses.

### Knowledge base setup

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_t1u2v3w4)

### Embeddings created

Embeddings are vector representations of text used for semantic search. I generated them using an embedding model and stored them in Chroma. The db/ folder holds the persisted vector database. This is critical for RAG because relevant context must be retrieved before response generation.

---

## Building the RAG API

In this step, I’m building a RAG API. An API is an interface that allows different applications to communicate with each other. FastAPI is a modern Python framework used to build high-performance APIs. I’m creating this to expose the RAG system as a web service that can accept questions and return AI-generated answers.

### FastAPI setup

### How the RAG API works

My RAG API works by receiving a question at the /query endpoint, retrieving relevant context from Chroma, passing the question and context to TinyLlama to generate an answer, and returning the response to the user.

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_f3g4h5i6)

---

## Testing the RAG API

In this step, I’m testing my RAG API. I’ll test it using Swagger UI, which is an interactive API documentation interface automatically generated by FastAPI. I’ll use it to send test requests to the /query endpoint and verify that the API returns correct responses.

### Testing the API

### API query breakdown

I queried my API using a POST request, which sends data in the request body. The API responded with an answer generated from the retrieved context.

![Image](http://learn.nextwork.org/lively_maroon_fierce_pear/uploads/ai-devops-api_g3h4i5j6)

### Swagger UI exploration

Swagger UI is an interactive API documentation interface. I used it to test my RAG API by sending requests to the /query endpoint. The best part about using Swagger UI was being able to test the API directly from the browser without writing any client code.

---
